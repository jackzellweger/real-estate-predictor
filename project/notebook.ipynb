{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8be09d55",
   "metadata": {},
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "af9805eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HELPERS\n",
    "import helpers\n",
    "import importlib\n",
    "importlib.reload(helpers)\n",
    "\n",
    "# OPERATING SYSTEM STUFF\n",
    "import os\n",
    "import io\n",
    "import gc\n",
    "\n",
    "# BASIC DATA SCIENCE\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# MACHINE LEARNING\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "\n",
    "# MODEL PACKAGING\n",
    "import joblib\n",
    "\n",
    "# API STUFF\n",
    "import xlrd\n",
    "import requests\n",
    "import json\n",
    "\n",
    "# SQL\n",
    "import time\n",
    "from sqlalchemy import create_engine, text, String, Integer, Float, Boolean, MetaData, Table, select\n",
    "from sqlalchemy.exc import ProgrammingError # ProgrammingError catches SQL write exceptions\n",
    "from sqlalchemy.sql import and_\n",
    "\n",
    "# GEOCODING\n",
    "from geopy.geocoders import GoogleV3\n",
    "\n",
    "# CONFIGURATION FILES\n",
    "import config\n",
    "importlib.reload(config)\n",
    "pd.set_option('display.float_format', '{:.6f}'.format)\n",
    "\n",
    "# OTHER\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827f3707",
   "metadata": {},
   "source": [
    "## Create databases / database connections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0fa97a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Silence errors\n",
    "os.environ['SQLALCHEMY_WARN_20'] = '0'\n",
    "os.environ['SQLALCHEMY_SILENCE_UBER_WARNING'] = '1'\n",
    "\n",
    "# Database params & credentials\n",
    "username = config.DB_USERNAME\n",
    "password = config.DB_PASSWORD\n",
    "hostname = config.DB_HOSTNAME\n",
    "database_name = config.DB_NAME\n",
    "\n",
    "# Table names\n",
    "geocodes_sql_table_name = 'geocodes'\n",
    "sales_sql_table_name = 'sales'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a15581c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Engine(mysql+pymysql://root:***@db/database_1)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "573ae528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database connection established successfully.\n",
      "SQLAlchemy warnings silenced.\n",
      "Table geocodes already exists\n",
      "Table 'geocodes' created from csv 'geocodes_export_backup.csv' successfully, or already exists.\n",
      "Column PRIMARY_KEY already exists in table geocodes.\n",
      "PRIMARY_KEY column values set in table geocodes.\n"
     ]
    }
   ],
   "source": [
    "# Attempt to establish a connection to the database\n",
    "engine = helpers.connect_to_database(username, password, hostname)\n",
    "\n",
    "if engine is not None:\n",
    "    # See file `helpers.py` for function documentation \n",
    "    engine = helpers.create_database(engine, database_name)\n",
    "    helpers.silence_warnings()\n",
    "    helpers.create_table_from_csv(\n",
    "        engine, 'geocodes', 'geocodes_export_backup.csv')\n",
    "    helpers.add_primary_key(\n",
    "        engine, 'geocodes', 'PRIMARY_KEY')\n",
    "    helpers.set_primary_key(\n",
    "        engine, 'geocodes', 'PRIMARY_KEY', \"`BOROUGH`, '_', `ADDRESS`\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f78bb892",
   "metadata": {},
   "source": [
    "## Download new sales data from NYC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a81f85bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty array that will hold our NYC Housing DataFrames\n",
    "data = []\n",
    "\n",
    "# Pull data from the NYC website\n",
    "for url in helpers.dataURLs:\n",
    "    # Read Excel file and skip the first 4 rows\n",
    "    df = pd.read_excel(url, skiprows=4, engine=\"openpyxl\")\n",
    "    data.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "12066813",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = helpers.combineHousingDataSets(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bc4c5071",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the 'BOROUGH' column to 'BOROUGH CODE'\n",
    "combined = combined.rename(columns={\"BOROUGH\": \"BOROUGH CODE\"})\n",
    "\n",
    "# Define the mapping for borough codes to borough names\n",
    "borough_mapping = {\n",
    "    1: \"MANHATTAN\",\n",
    "    2: \"BRONX\",\n",
    "    3: \"BROOKLYN\",\n",
    "    4: \"QUEENS\",\n",
    "    5: \"STATEN ISLAND\",\n",
    "}\n",
    "\n",
    "# Create a new 'BOROUGH' column based on 'BOROUGH CODE'\n",
    "borough = combined[\"BOROUGH CODE\"].map(borough_mapping)\n",
    "\n",
    "# Insert the new 'BOROUGH' column into the DataFrame right after the 'BOROUGH CODE' column\n",
    "combined.insert(loc=1, column=\"BOROUGH\", value=borough)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1642259",
   "metadata": {},
   "source": [
    "## Filter new sales data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9cff3714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows that contain the string 'N/A' anywhere in the address column...\n",
    "combined = combined[~combined['ADDRESS'].str.contains('N/A')]\n",
    "\n",
    "# Define thresholds for \"close to zero\"\n",
    "thresholds = {\n",
    "    'SALE PRICE': 100000,\n",
    "    'GROSS SQUARE FEET': 100,\n",
    "    'LAND SQUARE FEET': 100\n",
    "}\n",
    "\n",
    "# Filter outliers\n",
    "combined = helpers.filterOutliers(combined, thresholds, 0.25, 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1768985a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n# Create histograms for each column\\nfig, axs = plt.subplots(1, len(cols_to_check), figsize=(15, 5))\\nx\\n# Create histograms for each column\\nfor i, col in enumerate(cols_to_check):\\n    axs[i].hist(data_clean[col].dropna(), bins=30, edgecolor='black')\\n    axs[i].set_title(f'{col}')\\n\\n# Tight layout\\nplt.tight_layout()\\nplt.show()\\n\""
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Plot new distributions for sanity check\n",
    "'''\n",
    "# Create histograms for each column\n",
    "fig, axs = plt.subplots(1, len(cols_to_check), figsize=(15, 5))\n",
    "x\n",
    "# Create histograms for each column\n",
    "for i, col in enumerate(cols_to_check):\n",
    "    axs[i].hist(data_clean[col].dropna(), bins=30, edgecolor='black')\n",
    "    axs[i].set_title(f'{col}')\n",
    "\n",
    "# Tight layout\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "354596fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write the contents of `combined` to the `sales` SQL table...\n",
    "# FIXME: Is this necessary? Can we do away with the sales table SQL stuff\n",
    "with engine.connect() as connection:\n",
    "    combined.to_sql(sales_sql_table_name, con=engine, index=False, if_exists='replace')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3bbbab",
   "metadata": {},
   "source": [
    "# Update geocodes table"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c0d145a",
   "metadata": {},
   "source": [
    "### Set up tables for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df49ee88",
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.connect() as connection:\n",
    "    missing_rows = check_missing_rows(combined, geocodes_sql_table_name, engine)\n",
    "\n",
    "if missing_rows is not False:\n",
    "    tqdm.pandas()\n",
    "    missing_rows = missing_rows.progress_apply(helpers.geolocate, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c015421e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the index on the dataframe so that we ensure we don't have duplicates\n",
    "missing_rows.drop_duplicates(subset='PRIMARY_KEY', keep='first', inplace=True)\n",
    "missing_rows.set_index('PRIMARY_KEY', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "0ef86175",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the missing rows back to the SQL table with the geocodes\n",
    "with engine.connect() as connection:\n",
    "    missing_rows.to_sql(geocodes_sql_table_name, con=engine, if_exists='append', index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5e297a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test to see if the append worked. If `missing_rows` is empty, it did.\n",
    "with engine.connect() as connection:\n",
    "    geocodes_table_response = pd.read_sql_query(f\"SELECT * FROM {geocodes_sql_table_name}\", engine)\n",
    "\n",
    "missing_rows = geocodes_local[~geocodes_local['PRIMARY_KEY'].isin(geocodes_table_response['PRIMARY_KEY'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d29c76ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the DataFrames on 'BOROUGH' and 'ADDRESS'\n",
    "combined = combined.merge(geocodes_table_response[['BOROUGH', 'ADDRESS', 'LATITUDE', 'LONGITUDE']], \n",
    "                          on=['BOROUGH', 'ADDRESS'], \n",
    "                          how='left', \n",
    "                          suffixes=('', '_y'))\n",
    "\n",
    "# The merge could result in duplicate 'LATITUDE' and 'LONGITUDE'\n",
    "# columns if they exist in the `combined` dataframe.\n",
    "# We'll handle this by dropping the duplicate columns.\n",
    "\n",
    "# List of duplicate columns\n",
    "duplicate_columns = ['LATITUDE_y', 'LONGITUDE_y']\n",
    "\n",
    "# Drop duplicate columns from `combined`\n",
    "combined = combined.drop(columns=duplicate_columns, errors='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7a46a600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BOROUGH CODE': {1090: 1, 1891: 1, 4902: 1},\n",
       " 'BOROUGH': {1090: 'MANHATTAN', 1891: 'MANHATTAN', 4902: 'MANHATTAN'},\n",
       " 'NEIGHBORHOOD': {1090: 'CHELSEA',\n",
       "  1891: 'EAST VILLAGE',\n",
       "  4902: 'HARLEM-CENTRAL'},\n",
       " 'BUILDING CLASS CATEGORY': {1090: '22 STORE BUILDINGS',\n",
       "  1891: '07 RENTALS - WALKUP APARTMENTS',\n",
       "  4902: '01 ONE FAMILY DWELLINGS'},\n",
       " 'TAX CLASS AT PRESENT': {1090: '4', 1891: '2A', 4902: '1'},\n",
       " 'BLOCK': {1090: 776, 1891: 465, 4902: 1721},\n",
       " 'LOT': {1090: 68, 1891: 45, 4902: 27},\n",
       " 'EASEMENT': {1090: nan, 1891: nan, 4902: nan},\n",
       " 'BUILDING CLASS AT PRESENT': {1090: 'K2', 1891: 'C3', 4902: 'A5'},\n",
       " 'ADDRESS': {1090: '254 WEST 27TH STREET',\n",
       "  1891: '46 STUYVESANT STREET, 1',\n",
       "  4902: '20 WEST 123 STREET'},\n",
       " 'APARTMENT NUMBER': {1090: nan, 1891: nan, 4902: nan},\n",
       " 'ZIP CODE': {1090: 10001.0, 1891: 10003.0, 4902: 10027.0},\n",
       " 'RESIDENTIAL UNITS': {1090: 0.0, 1891: 4.0, 4902: 1.0},\n",
       " 'COMMERCIAL UNITS': {1090: 2.0, 1891: 0.0, 4902: 0.0},\n",
       " 'TOTAL UNITS': {1090: 2.0, 1891: 4.0, 4902: 1.0},\n",
       " 'LAND SQUARE FEET': {1090: 700.0, 1891: 794.0, 4902: 1640.0},\n",
       " 'GROSS SQUARE FEET': {1090: 2084.0, 1891: 3244.0, 4902: 3200.0},\n",
       " 'YEAR BUILT': {1090: 1930.0, 1891: 1900.0, 4902: 1899.0},\n",
       " 'TAX CLASS AT TIME OF SALE': {1090: 4, 1891: 2, 4902: 1},\n",
       " 'BUILDING CLASS AT TIME OF SALE': {1090: 'K2', 1891: 'C3', 4902: 'A5'},\n",
       " 'SALE PRICE': {1090: 2165000, 1891: 1800000, 4902: 2257500},\n",
       " 'SALE DATE': {1090: Timestamp('2022-09-30 00:00:00'),\n",
       "  1891: Timestamp('2022-07-27 00:00:00'),\n",
       "  4902: Timestamp('2022-07-28 00:00:00')}}"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined.head(3).to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "cfeedf93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BOROUGH CODE</th>\n",
       "      <th>BOROUGH</th>\n",
       "      <th>NEIGHBORHOOD</th>\n",
       "      <th>ADDRESS</th>\n",
       "      <th>PRIMARY_KEY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1090</th>\n",
       "      <td>1</td>\n",
       "      <td>MANHATTAN</td>\n",
       "      <td>CHELSEA</td>\n",
       "      <td>254 WEST 27TH STREET</td>\n",
       "      <td>MANHATTAN_254 WEST 27TH STREET</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1891</th>\n",
       "      <td>1</td>\n",
       "      <td>MANHATTAN</td>\n",
       "      <td>EAST VILLAGE</td>\n",
       "      <td>46 STUYVESANT STREET, 1</td>\n",
       "      <td>MANHATTAN_46 STUYVESANT STREET, 1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4902</th>\n",
       "      <td>1</td>\n",
       "      <td>MANHATTAN</td>\n",
       "      <td>HARLEM-CENTRAL</td>\n",
       "      <td>20 WEST 123 STREET</td>\n",
       "      <td>MANHATTAN_20 WEST 123 STREET</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      BOROUGH CODE    BOROUGH    NEIGHBORHOOD                  ADDRESS  \\\n",
       "1090             1  MANHATTAN         CHELSEA     254 WEST 27TH STREET   \n",
       "1891             1  MANHATTAN    EAST VILLAGE  46 STUYVESANT STREET, 1   \n",
       "4902             1  MANHATTAN  HARLEM-CENTRAL       20 WEST 123 STREET   \n",
       "\n",
       "                            PRIMARY_KEY  \n",
       "1090     MANHATTAN_254 WEST 27TH STREET  \n",
       "1891  MANHATTAN_46 STUYVESANT STREET, 1  \n",
       "4902       MANHATTAN_20 WEST 123 STREET  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataframe = pd.DataFrame(\n",
    "        {\n",
    "            \"BOROUGH CODE\": {1090: 1, 1891: 1, 4902: 1},\n",
    "            \"BOROUGH\": {1090: \"MANHATTAN\", 1891: \"MANHATTAN\", 4902: \"MANHATTAN\"},\n",
    "            \"NEIGHBORHOOD\": {\n",
    "                1090: \"CHELSEA\",\n",
    "                1891: \"EAST VILLAGE\",\n",
    "                4902: \"HARLEM-CENTRAL\",\n",
    "            },\n",
    "            \"ADDRESS\": {\n",
    "                1090: \"254 WEST 27TH STREET\",\n",
    "                1891: \"46 STUYVESANT STREET, 1\",\n",
    "                4902: \"20 WEST 123 STREET\",\n",
    "            },\n",
    "            \"PRIMARY_KEY\": {\n",
    "                # ...\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "\n",
    "test_dataframe[\"PRIMARY_KEY\"] = (\n",
    "            test_dataframe[\"BOROUGH\"] + \"_\" + test_dataframe[\"ADDRESS\"]\n",
    "        )\n",
    "\n",
    "test_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7ec195aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'BOROUGH CODE': [1, 1, 1],\n",
       " 'BOROUGH': ['MANHATTAN', 'MANHATTAN', 'MANHATTAN'],\n",
       " 'NEIGHBORHOOD': ['CHELSEA', 'EAST VILLAGE', 'HARLEM-CENTRAL'],\n",
       " 'ADDRESS': ['254 WEST 27TH STREET',\n",
       "  '46 STUYVESANT STREET, 1',\n",
       "  '20 WEST 123 STREET'],\n",
       " 'PRIMARY_KEY': ['MANHATTAN_254 WEST 27TH STREET',\n",
       "  'MANHATTAN_46 STUYVESANT STREET, 1',\n",
       "  'MANHATTAN_20 WEST 123 STREET']}"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataframe.head(3).to_dict(orient='list')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5360857",
   "metadata": {},
   "source": [
    "## Build mapping between NYC and Zillow housing categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1cc083c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: some categories were not be mapped, those rows were dropped.\n"
     ]
    }
   ],
   "source": [
    "# First, create the inverted mapping dictionary\n",
    "# invert_mapping = {building_class: zillow_cat for zillow_cat, building_class_list in helpers.category_mapping.items() for building_class in building_class_list}\n",
    "\n",
    "category_mapping = helpers.category_mapping\n",
    "\n",
    "# Then, use the map function to create the new column\n",
    "combined['GROUPED CATEGORY'] = combined['BUILDING CLASS CATEGORY'].map(category_mapping)\n",
    "\n",
    "# Check if there are any missing values in the new column (i.e., categories that couldn't be mapped)\n",
    "if combined['GROUPED CATEGORY'].isna().any():\n",
    "    combined = combined.dropna(subset=['GROUPED CATEGORY'])\n",
    "    print(\"Warning: some categories were not be mapped, those rows were dropped.\")\n",
    "\n",
    "combined.to_csv('for_model.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6dcb4a",
   "metadata": {},
   "source": [
    "## Choosing features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1672322e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BOROUGH CODE           0\n",
       "GROSS SQUARE FEET      0\n",
       "LAND SQUARE FEET       0\n",
       "GROUPED CATEGORY       0\n",
       "LATITUDE             814\n",
       "LONGITUDE            814\n",
       "SALE PRICE             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Select the features we are interested in\n",
    "selected_features = ['BOROUGH CODE', #'ZIP CODE',\n",
    "                     'GROSS SQUARE FEET', 'LAND SQUARE FEET', 'GROUPED CATEGORY', \n",
    "                     'LATITUDE', 'LONGITUDE', 'SALE PRICE']\n",
    "\n",
    "# Create a new DataFrame with only these features\n",
    "df = combined[selected_features]\n",
    "\n",
    "# Check for missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "f006c294",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BOROUGH CODE         0\n",
       "GROSS SQUARE FEET    0\n",
       "LAND SQUARE FEET     0\n",
       "GROUPED CATEGORY     0\n",
       "LATITUDE             0\n",
       "LONGITUDE            0\n",
       "SALE PRICE           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop rows with missing latitude or longitude\n",
    "df = df.dropna(subset=['LATITUDE', 'LONGITUDE'])\n",
    "\n",
    "# Check again for missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce75ecf5",
   "metadata": {},
   "source": [
    "## Encode using a `scikit-learn` encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7df16fc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the columns to be scaled and one-hot encoded\n",
    "cols_to_encode = ['BOROUGH CODE','GROUPED CATEGORY']\n",
    "\n",
    "cols_to_scale = ['GROSS SQUARE FEET',\n",
    "                 'LAND SQUARE FEET',\n",
    "                 'LATITUDE',\n",
    "                 'LONGITUDE',\n",
    "                 'SALE PRICE']\n",
    "\n",
    "# Initialize the transformers\n",
    "scaler = StandardScaler()\n",
    "ohe = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Define the preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('scale', scaler, cols_to_scale),\n",
    "        ('ohe', ohe, cols_to_encode)])\n",
    "\n",
    "# Apply the transformations\n",
    "df_processed = preprocessor.fit_transform(df)\n",
    "\n",
    "# Get the feature names after one-hot encoding\n",
    "ohe_feature_names = list(preprocessor.named_transformers_['ohe'].get_feature_names(input_features=cols_to_encode))\n",
    "\n",
    "# Combine the feature names\n",
    "feature_names = cols_to_scale + ohe_feature_names\n",
    "\n",
    "# Convert the array back into a DataFrame\n",
    "df_processed = pd.DataFrame(df_processed, columns=feature_names)\n",
    "\n",
    "# Drop rows with NaN values\n",
    "df_processed = df_processed.dropna()\n",
    "\n",
    "# Display the first few rows of the processed DataFrame\n",
    "#df_processed.head()\n",
    "\n",
    "df_encoded = df_processed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b66461",
   "metadata": {},
   "source": [
    "## Split the data into features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "35226f72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15792, 13), (3949, 13))"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the data into features and target\n",
    "X = df_encoded.drop('SALE PRICE', axis=1)\n",
    "y = df_encoded['SALE PRICE']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features\n",
    "X_train_scaled = X_train\n",
    "X_test_scaled = X_test\n",
    "\n",
    "X_train_scaled.shape, X_test_scaled.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc24ed3f",
   "metadata": {},
   "source": [
    "## Define random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "be063865",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.35992026281957035, 0.4265471961128181)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the model\n",
    "model = RandomForestRegressor(n_estimators=200, max_depth=10, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Make predictions on the training set and calculate the MAE\n",
    "y_train_pred = model.predict(X_train_scaled)\n",
    "mae_train = mean_absolute_error(y_train, y_train_pred)\n",
    "\n",
    "# Make predictions on the test set and calculate the MAE\n",
    "y_test_pred = model.predict(X_test_scaled)\n",
    "mae_test = mean_absolute_error(y_test, y_test_pred)\n",
    "\n",
    "mae_train, mae_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18567166",
   "metadata": {},
   "source": [
    "## Package up the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "bd2dd27e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['model/model.joblib']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dump the model to a shared docker volume...\n",
    "joblib.dump(model, 'model/model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "f8256686",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./model/preprocessor.joblib']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save the model\n",
    "joblib.dump(model, 'model.joblib')\n",
    "# Save the preprocessor\n",
    "joblib.dump(preprocessor, 'preprocessor.joblib')\n",
    "\n",
    "# Save the model\n",
    "joblib.dump(model, './model/model.joblib')\n",
    "# Save the preprocessor\n",
    "joblib.dump(preprocessor, './model/preprocessor.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503a9fe3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987e1d9a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
